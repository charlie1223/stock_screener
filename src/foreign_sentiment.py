"""
å¤–è³‡å‹•å‘åˆ†ææ¨¡çµ„ - ç¾è²¨ + æœŸè²¨äº¤å‰åˆ¤è®€å¤§ç›¤æ°›åœ

åˆ¤è®€é‚è¼¯:
  ç¾è²¨è²·è¶… + æœŸè²¨å¤šå–®å¢åŠ  = çµ•å°çœ‹å¤š
  ç¾è²¨è²·è¶… + æœŸè²¨ç©ºå–®å¢åŠ  = ç­–ç•¥å°æ²–
  ç¾è²¨è³£è¶… + æœŸè²¨ç©ºå–®å¢åŠ  = çµ•å°çœ‹ç©º
  ç¾è²¨è³£è¶… + æœŸè²¨å¤šå–®å¢åŠ  = åº•éƒ¨ä½ˆå±€
"""
import os
import logging
from datetime import datetime, timedelta
from typing import Dict, Optional

import pandas as pd
import requests

logger = logging.getLogger(__name__)


class ForeignSentimentAnalyzer:
    """å¤–è³‡ç¾è²¨+æœŸè²¨å‹•å‘åˆ†æå™¨"""

    # å››ç¨®æ°›åœç‹€æ…‹
    SENTIMENT_BULLISH = "çµ•å°çœ‹å¤š"
    SENTIMENT_HEDGE = "ç­–ç•¥å°æ²–"
    SENTIMENT_BEARISH = "çµ•å°çœ‹ç©º"
    SENTIMENT_BOTTOM = "åº•éƒ¨ä½ˆå±€"
    SENTIMENT_UNKNOWN = "è³‡æ–™ä¸è¶³"

    SENTIMENT_ICONS = {
        "çµ•å°çœ‹å¤š": "ğŸŸ¢",
        "ç­–ç•¥å°æ²–": "ğŸŸ¡",
        "çµ•å°çœ‹ç©º": "ğŸ”´",
        "åº•éƒ¨ä½ˆå±€": "ğŸ”µ",
        "è³‡æ–™ä¸è¶³": "âšª",
    }

    def __init__(self):
        self._token = os.getenv("FINMIND_API_TOKEN", "")

    def analyze(self) -> Dict:
        """
        åŸ·è¡Œå¤–è³‡å‹•å‘åˆ†æ
        Returns: {
            "sentiment": str,          # æ°›åœåˆ¤è®€ (çµ•å°çœ‹å¤š/ç­–ç•¥å°æ²–/çµ•å°çœ‹ç©º/åº•éƒ¨ä½ˆå±€)
            "icon": str,               # æ°›åœåœ–ç¤º
            "spot_net": float,         # ç¾è²¨æ·¨è²·è¶… (å„„å…ƒ)
            "spot_direction": str,     # ç¾è²¨æ–¹å‘ (è²·è¶…/è³£è¶…)
            "futures_oi_change": int,  # æœŸè²¨æœªå¹³å€‰å£æ•¸è®ŠåŒ–
            "futures_direction": str,  # æœŸè²¨æ–¹å‘ (å¤šå–®å¢/ç©ºå–®å¢)
            "detail": str,             # è©³ç´°èªªæ˜
            "date": str,               # è³‡æ–™æ—¥æœŸ
        }
        """
        logger.info("æ­£åœ¨åˆ†æå¤–è³‡å‹•å‘ (ç¾è²¨+æœŸè²¨)...")

        spot_data = self._fetch_spot_data()
        futures_data = self._fetch_futures_data()

        result = {
            "sentiment": self.SENTIMENT_UNKNOWN,
            "icon": self.SENTIMENT_ICONS[self.SENTIMENT_UNKNOWN],
            "spot_net": 0,
            "spot_direction": "N/A",
            "futures_oi_change": 0,
            "futures_direction": "N/A",
            "detail": "ç„¡æ³•å–å¾—è³‡æ–™",
            "date": datetime.now().strftime("%Y-%m-%d"),
        }

        if not spot_data and not futures_data:
            logger.warning("ç„¡æ³•å–å¾—å¤–è³‡ç¾è²¨/æœŸè²¨è³‡æ–™")
            return result

        # ç¾è²¨
        if spot_data:
            result["spot_net"] = spot_data["net_buy_billion"]
            result["spot_direction"] = "è²·è¶…" if spot_data["net_buy_billion"] > 0 else "è³£è¶…"
            result["date"] = spot_data.get("date", result["date"])

        # æœŸè²¨
        if futures_data:
            result["futures_oi_change"] = futures_data["oi_change"]
            result["futures_direction"] = "å¤šå–®å¢" if futures_data["oi_change"] > 0 else "ç©ºå–®å¢"

        # äº¤å‰åˆ¤è®€
        if spot_data and futures_data:
            spot_buy = spot_data["net_buy_billion"] > 0
            futures_long = futures_data["oi_change"] > 0

            if spot_buy and futures_long:
                result["sentiment"] = self.SENTIMENT_BULLISH
            elif spot_buy and not futures_long:
                result["sentiment"] = self.SENTIMENT_HEDGE
            elif not spot_buy and not futures_long:
                result["sentiment"] = self.SENTIMENT_BEARISH
            else:
                result["sentiment"] = self.SENTIMENT_BOTTOM

            result["icon"] = self.SENTIMENT_ICONS[result["sentiment"]]

            spot_label = f"{'è²·è¶…' if spot_buy else 'è³£è¶…'} {abs(spot_data['net_buy_billion']):.1f}å„„"
            futures_label = f"{'å¤šå–®å¢' if futures_long else 'ç©ºå–®å¢'} {abs(futures_data['oi_change']):,}å£"
            result["detail"] = f"ç¾è²¨{spot_label} / æœŸè²¨{futures_label}"

        elif spot_data:
            result["detail"] = f"ç¾è²¨{'è²·è¶…' if spot_data['net_buy_billion'] > 0 else 'è³£è¶…'} " \
                               f"{abs(spot_data['net_buy_billion']):.1f}å„„ (æœŸè²¨è³‡æ–™ä¸è¶³)"
        elif futures_data:
            result["detail"] = f"æœŸè²¨{'å¤šå–®å¢' if futures_data['oi_change'] > 0 else 'ç©ºå–®å¢'} " \
                               f"{abs(futures_data['oi_change']):,}å£ (ç¾è²¨è³‡æ–™ä¸è¶³)"

        logger.info(f"å¤–è³‡å‹•å‘: {result['icon']} {result['sentiment']} - {result['detail']}")
        return result

    def _fetch_spot_data(self) -> Optional[Dict]:
        """
        æŠ“å–å¤–è³‡ç¾è²¨è²·è³£è¶… (æ•´é«”å¸‚å ´)
        ä¾†æº: TWSE ä¸‰å¤§æ³•äººè²·è³£é‡‘é¡çµ±è¨ˆè¡¨
        ä¸å¸¶æ—¥æœŸåƒæ•¸ï¼ŒTWSE æœƒè‡ªå‹•å›å‚³æœ€è¿‘äº¤æ˜“æ—¥çš„è³‡æ–™
        Returns: {"net_buy_billion": float, "date": str}
        """
        try:
            url = "https://www.twse.com.tw/rwd/zh/fund/BFI82U"
            params = {"response": "json"}
            headers = {"User-Agent": "Mozilla/5.0"}

            response = requests.get(url, params=params, headers=headers, timeout=15)
            data = response.json()

            if data.get("stat") != "OK" or "data" not in data or not data["data"]:
                return None

            # å–å¾—è³‡æ–™æ—¥æœŸ
            api_date = data.get("date", "")
            if api_date and len(api_date) == 8:
                formatted_date = f"{api_date[:4]}-{api_date[4:6]}-{api_date[6:8]}"
            else:
                formatted_date = datetime.now().strftime("%Y-%m-%d")

            # æ‰¾å¤–è³‡é‚£ä¸€è¡Œ
            # TWSE æ ¼å¼: "å¤–è³‡åŠé™¸è³‡(ä¸å«å¤–è³‡è‡ªç‡Ÿå•†)" â†’ è¦æŠ“é€™è¡Œ
            #            "å¤–è³‡è‡ªç‡Ÿå•†" â†’ ä¸è¦é€™è¡Œ
            for row in data["data"]:
                name = str(row[0]).strip()
                if "å¤–è³‡åŠé™¸è³‡" in name or name == "å¤–è³‡(ä¸å«å¤–è³‡è‡ªç‡Ÿå•†)":
                    buy = int(str(row[1]).replace(",", ""))
                    sell = int(str(row[2]).replace(",", ""))
                    net = buy - sell  # å–®ä½: å…ƒ

                    return {
                        "net_buy_billion": round(net / 1_0000_0000, 2),  # è½‰å„„å…ƒ
                        "buy_billion": round(buy / 1_0000_0000, 2),
                        "sell_billion": round(sell / 1_0000_0000, 2),
                        "date": formatted_date,
                    }

            return None

        except Exception as e:
            logger.debug(f"å–å¾—å¤–è³‡ç¾è²¨è³‡æ–™å¤±æ•—: {e}")
            return None

    def _fetch_futures_data(self) -> Optional[Dict]:
        """
        æŠ“å–å¤–è³‡æœŸè²¨æœªå¹³å€‰è®ŠåŒ–
        ä¾†æº: FinMind TaiwanFuturesInstitutionalInvestors
              æˆ– æœŸäº¤æ‰€å®˜æ–¹ API
        Returns: {"oi_change": int, "oi_long": int, "oi_short": int, "date": str}
        """
        # å„ªå…ˆ FinMind
        result = self._fetch_futures_from_finmind()
        if result:
            return result

        # å‚™æ´: æœŸäº¤æ‰€
        return self._fetch_futures_from_taifex()

    def _fetch_futures_from_finmind(self) -> Optional[Dict]:
        """å¾ FinMind å–å¾—å¤–è³‡æœŸè²¨æœªå¹³å€‰"""
        try:
            end_date = datetime.now().strftime("%Y-%m-%d")
            start_date = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")

            url = "https://api.finmindtrade.com/api/v4/data"
            params = {
                "dataset": "TaiwanFuturesInstitutionalInvestors",
                "start_date": start_date,
                "end_date": end_date,
            }
            if self._token:
                params["token"] = self._token

            response = requests.get(url, params=params, timeout=15)
            result = response.json()

            if result.get("status") not in [200, "200"] or not result.get("data"):
                return None

            df = pd.DataFrame(result["data"])
            if df.empty:
                return None

            # ç¯©é¸å°æŒ‡æœŸ (TX) + å¤–è³‡
            tx_df = df[
                (df["name"].str.contains("å¤–è³‡", na=False)) &
                (df["contract_id"].str.contains("TX", na=False))
            ]

            if tx_df.empty:
                return None

            # å–æœ€æ–°å…©å¤©è¨ˆç®— OI è®ŠåŒ–
            dates = sorted(tx_df["date"].unique())
            if len(dates) < 2:
                # åªæœ‰ä¸€å¤©è³‡æ–™ï¼Œçœ‹ç•¶å¤©æœªå¹³å€‰æ·¨é¡
                latest = tx_df[tx_df["date"] == dates[-1]]
                oi_long = latest["open_interest_long"].sum()
                oi_short = latest["open_interest_short"].sum()
                return {
                    "oi_change": int(oi_long - oi_short),
                    "oi_long": int(oi_long),
                    "oi_short": int(oi_short),
                    "date": dates[-1],
                }

            latest = tx_df[tx_df["date"] == dates[-1]]
            prev = tx_df[tx_df["date"] == dates[-2]]

            latest_net = latest["open_interest_long"].sum() - latest["open_interest_short"].sum()
            prev_net = prev["open_interest_long"].sum() - prev["open_interest_short"].sum()

            return {
                "oi_change": int(latest_net - prev_net),
                "oi_long": int(latest["open_interest_long"].sum()),
                "oi_short": int(latest["open_interest_short"].sum()),
                "oi_net": int(latest_net),
                "date": dates[-1],
            }

        except Exception as e:
            logger.debug(f"FinMind æœŸè²¨è³‡æ–™å¤±æ•—: {e}")
            return None

    def _fetch_futures_from_taifex(self) -> Optional[Dict]:
        """
        å¾æœŸäº¤æ‰€å–å¾—å¤–è³‡æœŸè²¨æœªå¹³å€‰ (å‚™æ´)
        ä¾†æº: æœŸäº¤æ‰€ã€Œä¸‰å¤§æ³•äºº-å€åˆ†å„æœŸè²¨å¥‘ç´„ã€
        æŠ“æœ€è¿‘å…©å€‹äº¤æ˜“æ—¥çš„å¤–è³‡å°æŒ‡æœŸæœªå¹³å€‰ï¼Œè¨ˆç®—æ·¨é¡è®ŠåŒ–
        """
        try:
            from io import StringIO

            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
                "Referer": "https://www.taifex.com.tw/cht/3/futContractsDate",
            }

            # æŠ“æœ€è¿‘ 5 å¤© (è·³éé€±æœ«/å‡æ—¥ï¼Œéœ€è¦è‡³å°‘ 2 å€‹äº¤æ˜“æ—¥çš„è³‡æ–™)
            oi_records = []
            for days_ago in range(5):
                target_date = datetime.now() - timedelta(days=days_ago)
                date_str = target_date.strftime("%Y/%m/%d")

                url = "https://www.taifex.com.tw/cht/3/futContractsDate"
                params = {
                    "queryType": "1",
                    "doQuery": "1",
                    "queryDate": date_str,
                    "commodityId": "TXF",
                }

                response = requests.get(url, params=params, headers=headers, timeout=15)
                if response.status_code != 200:
                    continue

                try:
                    dfs = pd.read_html(StringIO(response.text))
                except ValueError:
                    continue

                if not dfs:
                    continue

                df = dfs[0]
                # æ‰¾å¤–è³‡ + è‡ºè‚¡æœŸè²¨é‚£ä¸€è¡Œ
                oi_net = self._parse_taifex_foreign_oi(df)
                if oi_net is not None:
                    oi_records.append({
                        "date": target_date.strftime("%Y-%m-%d"),
                        "oi_net": oi_net["oi_net"],
                        "oi_long": oi_net["oi_long"],
                        "oi_short": oi_net["oi_short"],
                    })

                # æœ‰å…©å¤©è³‡æ–™å°±å¤ äº†
                if len(oi_records) >= 2:
                    break

            if not oi_records:
                return None

            latest = oi_records[0]

            if len(oi_records) >= 2:
                prev = oi_records[1]
                oi_change = latest["oi_net"] - prev["oi_net"]
            else:
                # åªæœ‰ä¸€å¤©ï¼Œç”¨ç•¶å¤©æ·¨é¡
                oi_change = latest["oi_net"]

            return {
                "oi_change": oi_change,
                "oi_long": latest["oi_long"],
                "oi_short": latest["oi_short"],
                "oi_net": latest["oi_net"],
                "date": latest["date"],
            }

        except Exception as e:
            logger.debug(f"æœŸäº¤æ‰€æœŸè²¨è³‡æ–™å¤±æ•—: {e}")
            return None

    def _parse_taifex_foreign_oi(self, df: pd.DataFrame) -> Optional[Dict]:
        """
        è§£ææœŸäº¤æ‰€è¡¨æ ¼ï¼Œæ‰¾å‡ºå¤–è³‡å°æŒ‡æœŸæœªå¹³å€‰å£æ•¸
        è¡¨æ ¼çµæ§‹ (MultiIndex columns):
          [0] åºè™Ÿ [1] å•†å“åç¨± [2] èº«ä»½åˆ¥
          [3-8] äº¤æ˜“å£æ•¸: å¤šæ–¹å£æ•¸/é‡‘é¡, ç©ºæ–¹å£æ•¸/é‡‘é¡, æ·¨é¡å£æ•¸/é‡‘é¡
          [9-14] æœªå¹³å€‰: å¤šæ–¹å£æ•¸/é‡‘é¡, ç©ºæ–¹å£æ•¸/é‡‘é¡, æ·¨é¡å£æ•¸/é‡‘é¡
        """
        try:
            for idx, row in df.iterrows():
                vals = [str(v).strip() for v in row.values]
                # æ‰¾ "è‡ºè‚¡æœŸè²¨" + "å¤–è³‡" çš„é‚£ä¸€è¡Œ
                if "è‡ºè‚¡æœŸè²¨" in vals[1] and "å¤–è³‡" in vals[2]:
                    oi_long = int(str(row.iloc[9]).replace(",", ""))
                    oi_short = int(str(row.iloc[11]).replace(",", ""))
                    oi_net = int(str(row.iloc[13]).replace(",", ""))
                    return {
                        "oi_long": oi_long,
                        "oi_short": oi_short,
                        "oi_net": oi_net,
                    }
        except (ValueError, IndexError) as e:
            logger.debug(f"è§£ææœŸäº¤æ‰€è¡¨æ ¼å¤±æ•—: {e}")

        return None
