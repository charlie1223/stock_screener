"""
å¤šé ­è‚¡æ± è¿½è¹¤ç³»çµ±
- è¿½è¹¤å‡ç·šå¤šé ­æ’åˆ—çš„è‚¡ç¥¨ï¼ˆé«”è³ªè¿½è¹¤ï¼‰
- è¨˜éŒ„æ¯æ—¥è®ŠåŒ–ï¼šæ–°é€²/ç§»å‡º/æŒçºŒå¤©æ•¸
- èˆ‡æ¯æ—¥è¨Šè™Ÿç¯©é¸åˆ†é–‹
"""
import pandas as pd
import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging

from src.data.fetcher import DataFetcher
from config.settings import DATA_OUTPUT_DIR

logger = logging.getLogger(__name__)

# å¤šé ­è‚¡æ± è³‡æ–™å­˜æ”¾è·¯å¾‘
POOL_DATA_DIR = DATA_OUTPUT_DIR / "bullish_pool"


class BullishPoolTracker:
    """
    å¤šé ­è‚¡æ± è¿½è¹¤å™¨
    è¿½è¹¤æ¢ä»¶ï¼ˆé«”è³ªæ¢ä»¶ï¼Œä¸å«ç•¶æ—¥æ¼²å¹…ï¼‰ï¼š
    - å‡ç·šå¤šé ­æ’åˆ— (MA5 > MA10 > MA20 > MA60)
    - è‚¡åƒ¹ç«™ä¸Šæ‰€æœ‰å‡ç·š
    - 60æ—¥ç·šå‘ä¸Š
    """

    def __init__(self, data_fetcher: DataFetcher = None):
        self.data_fetcher = data_fetcher or DataFetcher()
        self.pool_dir = POOL_DATA_DIR
        self.pool_dir.mkdir(parents=True, exist_ok=True)
        self.ma_periods = [5, 10, 20, 60]

    def _get_pool_file(self, date: str = None) -> Path:
        """å–å¾—æŒ‡å®šæ—¥æœŸçš„è‚¡æ± æª”æ¡ˆè·¯å¾‘"""
        if date is None:
            date = datetime.now().strftime("%Y%m%d")
        return self.pool_dir / f"pool_{date}.json"

    def _get_history_file(self) -> Path:
        """å–å¾—æ­·å²è¿½è¹¤æª”æ¡ˆè·¯å¾‘"""
        return self.pool_dir / "history.json"

    def load_pool(self, date: str = None) -> Dict:
        """è¼‰å…¥æŒ‡å®šæ—¥æœŸçš„è‚¡æ± è³‡æ–™"""
        pool_file = self._get_pool_file(date)
        if pool_file.exists():
            with open(pool_file, "r", encoding="utf-8") as f:
                return json.load(f)
        return {}

    def save_pool(self, pool_data: Dict, date: str = None):
        """å„²å­˜è‚¡æ± è³‡æ–™"""
        pool_file = self._get_pool_file(date)
        with open(pool_file, "w", encoding="utf-8") as f:
            json.dump(pool_data, f, ensure_ascii=False, indent=2)
        logger.info(f"å¤šé ­è‚¡æ± å·²å„²å­˜: {pool_file}")

    def load_history(self) -> Dict:
        """è¼‰å…¥æ­·å²è¿½è¹¤è³‡æ–™"""
        history_file = self._get_history_file()
        if history_file.exists():
            with open(history_file, "r", encoding="utf-8") as f:
                return json.load(f)
        return {"stocks": {}, "last_update": None}

    def save_history(self, history: Dict):
        """å„²å­˜æ­·å²è¿½è¹¤è³‡æ–™"""
        history_file = self._get_history_file()
        with open(history_file, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=2)

    def check_bullish_condition(self, stock_id: str) -> Tuple[bool, Dict]:
        """
        æª¢æŸ¥å–®ä¸€è‚¡ç¥¨æ˜¯å¦ç¬¦åˆå¤šé ­æ¢ä»¶
        Returns: (is_bullish, details)
        """
        hist = self.data_fetcher.get_historical_data(stock_id, days=70)
        if hist.empty or len(hist) < 60:
            return False, {}

        # è¨ˆç®—å‡ç·š
        ma_values = {}
        for period in self.ma_periods:
            ma_values[period] = hist["close"].tail(period).mean()

        current_price = hist["close"].iloc[-1]

        # æª¢æŸ¥æ¢ä»¶
        # 1. è‚¡åƒ¹ç«™ä¸Šæ‰€æœ‰å‡ç·š
        above_all_ma = all(current_price > ma_values[p] for p in self.ma_periods)

        # 2. å‡ç·šå¤šé ­æ’åˆ— (MA5 > MA10 > MA20 > MA60)
        ma_bullish = (
            ma_values[5] > ma_values[10] > ma_values[20] > ma_values[60]
        )

        # 3. 60æ—¥ç·šå‘ä¸Š (æ¯”è¼ƒæœ€è¿‘5æ—¥çš„MA60)
        if len(hist) >= 65:
            ma60_5days_ago = hist["close"].iloc[-65:-5].tail(60).mean()
            ma60_trending_up = ma_values[60] > ma60_5days_ago
        else:
            ma60_trending_up = True  # è³‡æ–™ä¸è¶³æ™‚é è¨­ç‚º True

        is_bullish = above_all_ma and ma_bullish and ma60_trending_up

        details = {
            "price": current_price,
            "ma_values": ma_values,
            "above_all_ma": above_all_ma,
            "ma_bullish": ma_bullish,
            "ma60_trending_up": ma60_trending_up
        }

        return is_bullish, details

    def scan_bullish_stocks(self, stock_df: pd.DataFrame = None) -> pd.DataFrame:
        """
        æƒææ‰€æœ‰è‚¡ç¥¨ï¼Œæ‰¾å‡ºç¬¦åˆå¤šé ­æ¢ä»¶çš„è‚¡ç¥¨
        Args:
            stock_df: è‚¡ç¥¨æ¸…å–® DataFrame (éœ€åŒ…å« stock_id, stock_name)
                     è‹¥ç‚º None å‰‡è‡ªå‹•ç²å–
        Returns:
            ç¬¦åˆå¤šé ­æ¢ä»¶çš„è‚¡ç¥¨ DataFrame
        """
        if stock_df is None:
            stock_df = self.data_fetcher.get_all_stocks_realtime()

        if stock_df.empty:
            logger.warning("ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®")
            return pd.DataFrame()

        # åŠ å…¥ç”¢æ¥­åˆ†é¡
        industry_map = self.data_fetcher.get_industry_classification()

        logger.info(f"é–‹å§‹æƒæå¤šé ­è‚¡ç¥¨ï¼Œå…± {len(stock_df)} æª”...")
        bullish_stocks = []
        total = len(stock_df)

        for idx, row in stock_df.iterrows():
            stock_id = row["stock_id"]

            # é€²åº¦é¡¯ç¤º
            if (idx + 1) % 100 == 0:
                logger.info(f"æƒæé€²åº¦: {idx + 1}/{total}")

            is_bullish, details = self.check_bullish_condition(stock_id)

            if is_bullish:
                bullish_stocks.append({
                    "stock_id": stock_id,
                    "stock_name": row.get("stock_name", ""),
                    "industry": industry_map.get(stock_id, "æœªåˆ†é¡"),
                    "price": row.get("price", details.get("price", 0)),
                    "change_pct": row.get("change_pct", 0),
                    "ma5": round(details["ma_values"][5], 2),
                    "ma10": round(details["ma_values"][10], 2),
                    "ma20": round(details["ma_values"][20], 2),
                    "ma60": round(details["ma_values"][60], 2),
                })

        result_df = pd.DataFrame(bullish_stocks)
        logger.info(f"å¤šé ­è‚¡æ± æƒæå®Œæˆ: å…± {len(result_df)} æª”ç¬¦åˆæ¢ä»¶")
        return result_df

    def update_pool(self, bullish_df: pd.DataFrame) -> Dict:
        """
        æ›´æ–°å¤šé ­è‚¡æ± ï¼Œè¨ˆç®—æ–°é€²/ç§»å‡º/æŒçºŒå¤©æ•¸
        Args:
            bullish_df: ä»Šæ—¥å¤šé ­è‚¡ç¥¨ DataFrame
        Returns:
            æ›´æ–°çµæœ {new_entries, removed, continued, pool_data}
        """
        today = datetime.now().strftime("%Y%m%d")
        yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")

        # è¼‰å…¥æ˜¨æ—¥è‚¡æ± å’Œæ­·å²
        yesterday_pool = self.load_pool(yesterday)
        history = self.load_history()

        yesterday_ids = set(yesterday_pool.get("stocks", {}).keys())
        today_ids = set(bullish_df["stock_id"].tolist()) if not bullish_df.empty else set()

        # è¨ˆç®—è®ŠåŒ–
        new_entries = today_ids - yesterday_ids
        removed = yesterday_ids - today_ids
        continued = today_ids & yesterday_ids

        # æ›´æ–°æ­·å²è¿½è¹¤ (é€£çºŒå¤©æ•¸)
        stocks_history = history.get("stocks", {})

        # æ–°é€²è‚¡ç¥¨
        for sid in new_entries:
            stocks_history[sid] = {
                "first_date": today,
                "consecutive_days": 1,
                "last_date": today
            }

        # æŒçºŒè‚¡ç¥¨
        for sid in continued:
            if sid in stocks_history:
                stocks_history[sid]["consecutive_days"] += 1
                stocks_history[sid]["last_date"] = today
            else:
                stocks_history[sid] = {
                    "first_date": today,
                    "consecutive_days": 1,
                    "last_date": today
                }

        # ç§»å‡ºè‚¡ç¥¨ (ä¿ç•™è¨˜éŒ„ä½†æ¨™è¨˜)
        for sid in removed:
            if sid in stocks_history:
                stocks_history[sid]["removed_date"] = today

        history["stocks"] = stocks_history
        history["last_update"] = today
        self.save_history(history)

        # å»ºç«‹ä»Šæ—¥è‚¡æ± è³‡æ–™
        pool_data = {"date": today, "stocks": {}}
        for _, row in bullish_df.iterrows():
            sid = row["stock_id"]
            pool_data["stocks"][sid] = {
                "stock_name": row.get("stock_name", ""),
                "industry": row.get("industry", "æœªåˆ†é¡"),
                "price": row.get("price", 0),
                "change_pct": row.get("change_pct", 0),
                "consecutive_days": stocks_history.get(sid, {}).get("consecutive_days", 1)
            }

        self.save_pool(pool_data, today)

        return {
            "new_entries": list(new_entries),
            "removed": list(removed),
            "continued": list(continued),
            "pool_data": pool_data
        }

    def get_pool_summary(self, pool_data: Dict = None) -> Dict:
        """
        å–å¾—è‚¡æ± æ‘˜è¦çµ±è¨ˆ
        """
        if pool_data is None:
            pool_data = self.load_pool()

        stocks = pool_data.get("stocks", {})
        if not stocks:
            return {"total": 0, "by_industry": {}, "by_days": {}}

        # ç”¢æ¥­åˆ†å¸ƒ
        industry_counts = {}
        for sid, info in stocks.items():
            ind = info.get("industry", "æœªåˆ†é¡")
            industry_counts[ind] = industry_counts.get(ind, 0) + 1

        # é€£çºŒå¤©æ•¸åˆ†å¸ƒ
        days_counts = {}
        for sid, info in stocks.items():
            days = info.get("consecutive_days", 1)
            if days >= 10:
                key = "10å¤©ä»¥ä¸Š"
            elif days >= 5:
                key = "5-9å¤©"
            else:
                key = f"{days}å¤©"
            days_counts[key] = days_counts.get(key, 0) + 1

        return {
            "total": len(stocks),
            "by_industry": dict(sorted(industry_counts.items(), key=lambda x: -x[1])),
            "by_days": days_counts
        }

    def print_pool_report(self, update_result: Dict):
        """è¼¸å‡ºå¤šé ­è‚¡æ± å ±å‘Š"""
        print("\n" + "=" * 80)
        print("  ã€å¤šé ­è‚¡æ± å ±å‘Šã€‘- é«”è³ªè¿½è¹¤")
        print("=" * 80)

        pool_data = update_result.get("pool_data", {})
        stocks = pool_data.get("stocks", {})

        print(f"\n  ä»Šæ—¥å¤šé ­è‚¡æ± : {len(stocks)} æª”")

        # æ–°é€²è‚¡ç¥¨
        new_entries = update_result.get("new_entries", [])
        if new_entries:
            print(f"\n  ğŸ†• æ–°é€²å¤šé ­ ({len(new_entries)} æª”):")
            for sid in new_entries[:10]:
                info = stocks.get(sid, {})
                print(f"     {sid} {info.get('stock_name', '')} [{info.get('industry', '')}]")
            if len(new_entries) > 10:
                print(f"     ... é‚„æœ‰ {len(new_entries) - 10} æª”")

        # ç§»å‡ºè‚¡ç¥¨
        removed = update_result.get("removed", [])
        if removed:
            print(f"\n  âš ï¸  è·Œå‡ºå¤šé ­ ({len(removed)} æª”):")
            for sid in removed[:10]:
                print(f"     {sid}")
            if len(removed) > 10:
                print(f"     ... é‚„æœ‰ {len(removed) - 10} æª”")

        # é€£çºŒå¤šé ­æ’è¡Œ (å‰10å)
        if stocks:
            sorted_stocks = sorted(
                stocks.items(),
                key=lambda x: x[1].get("consecutive_days", 0),
                reverse=True
            )[:10]

            print(f"\n  ğŸ† é€£çºŒå¤šé ­æ’è¡Œ (å‰10å):")
            for sid, info in sorted_stocks:
                days = info.get("consecutive_days", 1)
                print(f"     {sid} {info.get('stock_name', ''):<8} "
                      f"[{info.get('industry', '')}] - é€£çºŒ {days} å¤©")

        # ç”¢æ¥­åˆ†å¸ƒ
        summary = self.get_pool_summary(pool_data)
        if summary["by_industry"]:
            print(f"\n  ğŸ“Š ç”¢æ¥­åˆ†å¸ƒ:")
            for ind, cnt in list(summary["by_industry"].items())[:8]:
                print(f"     {ind}: {cnt} æª”")

        print("\n" + "=" * 80)
